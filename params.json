{"name":"coreos","tagline":"How to setup a CoreOS cluster on EC2 with metrics, logging and continuous deployment","body":"### Intro\r\nDocker is a revolution.  If you believe that, then the next question is how will you manage all these containers?  CoreOS is one answer.  The best way to learn something is get your hands dirty and play with it.  If you follow along here you will get more familiar with thinking about a world made only of containers and learn a few things along the way, like:\r\n* Docker: docker boot2docker dockerhub btrfs\r\n* CoreOS: systemd etcd fleet\r\n* AWS: CloudFormation ELB ASG SecurityGroups\r\n* 3rd Party: DataDog Loggly CircleCI\r\n* Bitcoin: bitcoin namecoin blockchain\r\n\r\n### Summary\r\nHere's a high level view of what we'll be doing: \r\n* Setup 3 node CoreOS cluster via Cloud Formation fronted by an ELB\r\n* Deploy monitoring and logging containers\r\n* Deploy http server container\r\n* Setup .bit domain\r\n* Add automated build, test and deploy\r\n\r\n### Setup Docker (assuming OSX)\r\n* [Install](https://www.virtualbox.org/) virtualbox, it's needed by boot2docker.\r\n* [Install](https://docs.docker.com/installation/mac/) docker and boot2docker.\r\n* [Create an account](https://hub.docker.com/) on dockerhub.\r\n\r\n### Setup AWS\r\n* [Create an account](https://aws.amazon.com/) with Amazon AWS.  You will have to pay for your usage.  A single CoreOS cluster with an ELB is costing me about $3 a day.\r\n* Add an account via [IAM](https://aws.amazon.com/iam/) and save your AWS creds.\r\n* Generate an SSH keypair locally and upload the public key, or upload your existing public key:\r\n```\r\nssh-keygen -t rsa -f id_rsa\r\n```\r\n\r\n* [Install](http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-set-up.html) the AWS command line tools:\r\n```\r\nwget https://s3.amazonaws.com/aws-cli/awscli-bundle.zip\r\nunzip awscli-bundle.zip\r\nsudo ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws\r\n```\r\n\r\n* Add necessary environment variables to your ~/.bash_profile:\r\n```\r\n# AWS creds\r\nexport AWS_ACCESS_KEY_ID=XXXXXXXXXXXXXX\r\nexport AWS_SECRET_ACCESS_KEY=XXXXXXXXXXXXXXXXXXXXXX\r\nexport AWS_DEFAULT_REGION=us-west-1\r\nexport AWS_DEFAULT_OUTPUT=text\r\n```\r\n\r\n### Launch CloudFormation Stack\r\nUsing the template provided from CoreOS, modify the necessary parameters and fire up [CloudFormation](http://docs.aws.amazon.com/cli/latest/reference/cloudformation/create-stack.html).  If you already had an AWS account make sure it is Default-VPC and not EC2-Classic or the the CloudFormation template may not work.\r\n\r\nThe following parameters are passed to the template.  Don’t forget to [generate](https://discovery.etcd.io/new) a new [DiscoveryURL](https://coreos.com/docs/cluster-management/setup/cluster-discovery/):  \r\n* DiscoveryURL: used by etcd to first discover peers.\r\n* InstanceType: EC2 instance type.\r\n* KeyPair: the name of the SSH keypair you uploaded to AWS.\r\n\r\nThe template sets the following defaults.  If you want something else, [other templates](https://coreos.com/docs/running-coreos/cloud-providers/ec2/) are available from CoreOS:\r\n* CoreOS channel: alpha\r\n* PV vs HVM: HVM\r\n* Region: us-west-1\r\n\r\n```\r\naws cloudformation create-stack --stack-name CoreOS-alpha --template-url https://s3.amazonaws.com/coreos.com/dist/aws/coreos-alpha-hvm.template --parameters ParameterKey=DiscoveryURL,ParameterValue=https://discovery.etcd.io/0ffffffffffffffffffffffffffff,UsePreviousValue=true ParameterKey=InstanceType,ParameterValue=t2.small,UsePreviousValue=true ParameterKey=KeyPair,ParameterValue=daniel,UsePreviousValue=true\r\n```\r\n\r\nWatch the magic happen in your AWS web console.  Once created, adjust ASG Max instances to 3 (to prevent ballooning resource use).\r\n\r\n### Verify connectivity\r\nNow you should have 3 EC2 instances in an ASG, along with a SecurityGroup.  Let's login to the hosts and [explore the cluster](https://coreos.com/docs/launching-containers/launching/fleet-using-the-client/#exploring-the-cluster) a little.\r\n\r\n* Get the public IPs of the instances:\r\n```\r\naws ec2 describe-instances --filter Name=tag:Name,Values=CoreOS-alpha | grep ASSOCIATION | sort | uniq | awk '{print $NF}'\r\n111.111.111.200\r\n111.111.111.201\r\n111.111.111.202\r\n```\r\n\r\n* SSH to the public IP of each instance.  Try out some [fleetctl](https://coreos.com/docs/launching-containers/launching/launching-containers-fleet/) and [etcdctl](https://coreos.com/docs/distributed-configuration/getting-started-with-etcd/) commands.\r\n\r\nfleetctl communicates over SSH so using ‘-A' allows for forwarding ssh connections, useful for when running fleetctl on the hosts.  etcd acts a global configuration database that you can use for all sorts of things.  Try setting and getting some keys and watching them instantly appear on other nodes.\r\n```\r\nssh -A core@111.111.111.200\r\nfleetctl list-machines\r\netcdctl ls\r\n```\r\n\r\n* [Download](https://github.com/coreos/fleet/releases) fleetctl to your local workstation\r\n\r\n* Load your private key into ssh-agent (needed to make remote fleetctl work as it operates over SSH):\r\n```\r\nssh-add ~/.ssh/id_rsa\r\nssh-add -l\r\n```\r\n\r\n* Add the IP of one of the hosts to your local ~/.bash_profile for remote comms:\r\n```\r\n# Connect to remote CoreOS on EC2\r\nexport FLEETCTL_TUNNEL=111.111.111.200:22\r\n```\r\n\r\n* source and verify:\r\n```\r\n.~/.bash_profile\r\nfleetctl list-machines\r\n```\r\n\r\n### Upload and start DataDog monitoring service\r\nDatadog provides a [container](https://www.datadoghq.com/2014/08/monitor-coreos-scale-datadog/) for setting up host monitoring.  This is a container that runs on your CoreOS hosts.  You should never need to install additional tools on the host itself.  The container monitors resources on the host by inspecting the local /proc filesystem.  Normally containers are not allowed to see outside their world, but if run in '--privileged' mode this can be overridden.\r\n\r\nThis is also a good time to learn about [fleet unit files](https://coreos.com/docs/launching-containers/launching/fleet-unit-files/), which are based on [systemd](https://coreos.com/docs/launching-containers/launching/getting-started-with-systemd/).\r\n\r\n* [Sign up](https://www.datadoghq.com/) for datadog.  It’s free.\r\n\r\n* Put your personal API key into etcd (run from any host):\r\n```\r\netcdctl set /ddapikey XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\r\n```\r\n\r\n* Fork [danielnbarbosa/docker-dd-agent](https://github.com/danielnbarbosa/docker-dd-agent) github repo via the web UI.\r\n\r\n* Replace my dockerhub id with your own:\r\n```\r\nsed -i -e \"s/danielnbarbosa/YOUR_DOCKERHUB_ID/g\" *\r\nrm *-e\r\n```\r\n\r\n* Upload and start fleet units:\r\n```\r\nfleetctl submit dd-agent@.service\r\nfleetctl start dd-agent@{1..3}.service\r\n```\r\n\r\n* Verify containers started.  There should be one on each host.\r\n```\r\nfleetctl list-units\r\n```\r\n\r\n* Verify metrics are flowing in the DataDog web UI.\r\n\r\n### Upload and start Loggly log service\r\nLoggly also offers a [container](https://www.loggly.com/blog/centralize-logs-docker-containers/) for centralized logging.  This is just a simple rsyslogd service that fowards the logs on to loggly.\r\n\r\nThe \"Docker Way\" (TM) says that you should never install more than one service in a container.  Containers are not VMs.  They wrap processes.  This means we won't be adding agents inside of the container for helping out with sending logs to a central server.  Instead we will install a logging container that other containers will forward their logs to.\r\n\r\n* [Sign up](https://www.loggly.com/) for loggly.  Also free.\r\n\r\n* Put your personal API key into etcd (run from any host):\r\n```\r\netcdctl set /logapikey XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\r\n```\r\n\r\n* Fork [danielnbarbosa/docker-loggly-agent](https://github.com/danielnbarbosa/docker-loggly-agent) github repo via the web UI.\r\n\r\n* Replace my dockerhub id with your own:\r\n```\r\nsed -i -e \"s/danielnbarbosa/YOUR_DOCKERHUB_ID/g\" *\r\nrm *-e\r\n```\r\n\r\n* Upload and start fleet units:\r\n```\r\nfleetctl submit loggly-agent@.service\r\nfleetctl start loggly-agent@{1..3}.service\r\n```\r\n\r\n* Verify containers started.  There should be one on each host.\r\n```\r\nfleetctl list-units\r\n```\r\n\r\n* Test logging from each host, substitute UDP port (49153) as appropriate:\r\n```\r\necho netcat:\"Host test log\" | ncat -u -w 1 127.0.0.1 49153\r\n```\r\n\r\n* Verify logs are flowing in the Loggly web UI.\r\n\r\n\r\n### Create ELB\r\n* Get your default VPC security group:\r\n```\r\naws ec2 describe-security-groups | grep SECURITYGROUPS | grep default | awk '{print $6}'\r\n```\r\n\r\n* Create the ELB passing in the security group id from above:\r\n```\r\naws elb create-load-balancer --load-balancer-name=lb-coreos-alpha --listeners Protocol=HTTP,LoadBalancerPort=80,InstanceProtocol=HTTP,InstancePort=80 --availability-zones us-west-1a us-west-1b --security-groups=sg-111aaa5c\r\n```\r\n\r\n* Get the 3 instances:\r\n```\r\naws ec2 describe-instances --filter Name=tag:Name,Values=CoreOS-alpha | grep INSTANCES | awk '{print $8}'\r\ni-8e1111d1\r\ni-8e1111d2\r\ni-8e1111d3\r\n```\r\n\r\n* Register instances with the ELB ids from above:\r\n```\r\naws elb register-instances-with-load-balancer --load-balancer-name lb-coreos-alpha --instances i-8e1111d1i-8e1111d2i-8e1111d3\r\n```\r\n\r\n* Drop healthy threshold to 2 so it doesn’t take so long for an instance to be brought back in service.  Note that the ELB will remain out of service until we deploy the http container.\r\n\r\n\r\n### Configure CoreOS cluster security groups\r\n* Allow all TCP ports (0-65535) internal to CoreOS security group (will make debugging easier)\r\n* Allow all TCP ports (0-65535) from default VPC (for the ELB and testing various services)\r\n\r\n### Upload and start noke.bit http service\r\nNow for the good part, an actual website.  Keep in mind the \"Docker Way\" (TM) is one service per container and that service runs in the foreground.  That's why if you follow the Dockerfile you'll see that nginx is set to 'daemon off'.  Also take note of how this container uses ['--link'](https://docs.docker.com/userguide/dockerlinks/) to link to the loggly logging container.  Using environment variables passed from the loggly container, nginx configures it's logs to be sent via syslog to the loggly container.\r\n\r\n* Fork [danielnbarbosa/docker-noke-nginx](https://github.com/danielnbarbosa/docker-noke-nginx) repo via the web UI\r\n\r\n* Replace my dockerhub id with your own:\r\n```\r\nsed -i -e \"s/danielnbarbosa/YOUR_DOCKERHUB_ID/g\" *\r\nrm *-e\r\n```\r\n\r\n* Upload and start fleet units:\r\n```\r\nfleetctl submit noke-nginx@.service\r\nfleetctl start noke-nginx@{1..3}.service\r\n```\r\n\r\n* Verify containers started.  There should be one on each host.\r\n```\r\nfleetctl list-units\r\n```\r\n\r\n### Setup DNS\r\nThis part I did all through the AWS web console, but you could do it via the command line tools if you wanted.  Also you'll have to pick your own domain name.  Feel free to forego the whole .bit thing if you don't want to bother with registering a .bit domain.\r\n\r\n* register noke.bit domain in route53\r\n* point root A record alias to ELB\r\n\r\n\r\n### Register your domain name\r\n.bit domains are registered on the namecoin blockchain.  Namecoin is a fork of bitcoin that uses the blockchain as a decentralized store of identity information, including the TLD .bit.  This is pretty cool because it basically acts as a decentralized domain registration service.  Unfortunately it's still a bit complicated to register these domains.  The directions below are for doing it yourself, but there are also [services](https://dotbit.me/) that will register them on your behalf, though this kind of defeats the whole decentralization thing.\r\n\r\n* [Download](https://github.com/namecoin/namecoin) namecoind\r\n\r\n* Build and compile namecoind.\r\n\r\n* Sync the blockchain.  This will take hours to days to complete.\r\n\r\n* Buy some namecoin.  This is still a bit complicated.  You’ll first need to [buy some bitcoin](https://www.coinbase.com) and then [find](https://btc-e.com/) [an](https://bter.com/) [exchange](https://www.cryptsy.com/) to exchange your bitcoin for namecoin.  Once you have the namecoin in your local wallet you can use your local namecoind to register a .bit domain (paying a small fee in namecoin for spam prevention).\r\n\r\n* [Register and update](http://dot-bit.org/HowToRegisterAndConfigureBitDomains) namecoin blockchain with new NS data.  You won't be able to use noke cause that's mine :).\r\n```\r\nnamecoind name_update d/noke '{\"ns\": [\"ns-389.awsdns-48.com\", \"ns-776.awsdns-33.net\", \"ns-1125.awsdns-12.org\", \"ns-1695.awsdns-19.co.uk\"]}'\r\n```\r\nDon’t forget to restart chrome in case the plugin has locally cached your domain.  Alternatively you can just hack your local hosts file or resolv.conf.\r\n\r\n\r\n### Rebalance btrfs\r\nbtrfs is the default storage driver used by docker.  You'll need to periodically [rebalance btrfs](https://coreos.com/docs/cluster-management/debugging/btrfs-troubleshooting/) on the CoreOS hosts to prevent them from running out of filesystem space.  Note that 'df -h' will lie to you, use 'sudo btrfs fi show' instead.\r\n```\r\nsudo btrfs fi show; sudo btrfs balance start /; sudo btrfs fi show\r\n```\r\n\r\n\r\n### Integrate Circle CI\r\nCircleCI is the bees knees.  Yes, that's what I said.  It is a super slick continuous integration and deployment tool that also supports building and testing docker containers.\r\n\r\n* [Sign up](https://circleci.com/) for Circle CI.  It's free for 1 container.\r\n\r\n* Generate a new SSH keypair locally for circleCI to use to access the hosts:\r\n```\r\nssh-keygen -t rsa -f id_circleci\r\n```\r\n\r\n* Add public key to ec2 instances:\r\n```\r\ncat ~/.ssh/id_circleci.pub\r\n```\r\non each host:\r\n```\r\nvi ~/.ssh/authorized_keys\r\n```\r\n\r\n* For each of the docker repos you forked:\r\n    * add project and follow repo in circle CI\r\n    * add private key (generated earlier) to circleCI project\r\n    * add dockerhub env vars to circeCI project:\r\n```\r\n    cat ~/.dockercfg\r\n    DOCKER_EMAIL=XXXXXXXXXXXX\r\n    DOCKER_AUTH=XXXXXXXXXXXXX\r\n```\r\n\r\n* Test an infrastructure build/deploy using docker-dd-agent repo:\r\n\r\nModify a file in the repo (like the IP address hardcoded into deploy.sh, cough):\r\n```\r\n    git add .\r\n    git commit -m “testing circleci\"\r\n    git push\r\n```\r\nWatch CircleCI build and deploy the container.\r\n\r\n* Test a front-end site buid/deploy using docker-noke-nginx:\r\n\r\nModify a file in the repo (like the IP address hardcoded into deploy.sh, cough):\r\n```\r\n    git add .\r\n    git commit -m “testing circleci\"\r\n    git push\r\n```\r\nWatch CircleCI build and deploy the container without taking the site down.  Sweet!","google":"UA-57003251-1","note":"Don't delete this file! It's used internally to help with page regeneration."}